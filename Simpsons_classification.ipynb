{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"submit.ipynb","provenance":[{"file_id":"1GO78KDwhTIzJavtcQjenx_jKXFusySAr","timestamp":1578243605955},{"file_id":"1slzf6-xJfqoMoRpVdNJuG0TSeUATPnRP","timestamp":1577575455215}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"fQlDjKcWcb1I"},"source":["\n","\n","## **Физтех-Школа Прикладной математики и информатики (ФПМИ) МФТИ**"]},{"cell_type":"markdown","metadata":{"id":"oG47vhLxKNln"},"source":["### Установка зависимостей"]},{"cell_type":"code","metadata":{"id":"_ITX8q-BMkKu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619174138254,"user_tz":-180,"elapsed":5316,"user":{"displayName":"Роберт Сафиуллин","photoUrl":"","userId":"12047560743282496128"}},"outputId":"2e8b46e6-3f7c-49cc-fca9-7fe98b423fe9"},"source":["!pip install -U torch torchvision"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already up-to-date: torch in /usr/local/lib/python3.7/dist-packages (1.8.1+cu101)\n","Requirement already up-to-date: torchvision in /usr/local/lib/python3.7/dist-packages (0.9.1+cu101)\n","Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n","Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n","Requirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"W-YekKLfK-3M","colab":{"base_uri":"https://localhost:8080/","height":418},"executionInfo":{"status":"error","timestamp":1619174179903,"user_tz":-180,"elapsed":5555,"user":{"displayName":"Роберт Сафиуллин","photoUrl":"","userId":"12047560743282496128"}},"outputId":"286c083b-0a7e-47e9-f6b1-e70c140a5660"},"source":["# установка подходящей версии torch\n","\n","!pip install wheel setuptools\n","!pip install wheel\n","\n","from os.path import exists\n","from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n","platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n","cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n","accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n","\n","!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n","import torch"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (0.36.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (56.0.0)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (0.36.2)\n"],"name":"stdout"},{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-2fa135b391ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mwheel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpep425tags\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_abbr_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_impl_ver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_abi_tag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mplatform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{}{}-{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_abbr_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_impl_ver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_abi_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mcuda_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetoutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ldconfig -p|grep cudart.so|sed -e 's/.*\\\\.\\\\([0-9]*\\\\)\\\\.\\\\([0-9]*\\\\)$/cu\\\\1\\\\2/'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wheel.pep425tags'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"WWgcwKwCLBfr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619174195240,"user_tz":-180,"elapsed":577,"user":{"displayName":"Роберт Сафиуллин","photoUrl":"","userId":"12047560743282496128"}},"outputId":"d574d1d6-1390-43a6-98a2-21d22304093c"},"source":["# we will verify that GPU is enabled for this notebook\n","# following should print: CUDA is available!  Training on GPU ...\n","# \n","# if it prints otherwise, then you need to enable GPU: \n","# from Menu > Runtime > Change Runtime Type > Hardware Accelerator > GPU\n","\n","import torch\n","import numpy as np\n","\n","train_on_gpu = torch.cuda.is_available()\n","\n","if not train_on_gpu:\n","    print('CUDA is not available.  Training on CPU ...')\n","else:\n","    print('CUDA is available!  Training on GPU ...')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["CUDA is available!  Training on GPU ...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MXno2OSeLF3e","colab":{"base_uri":"https://localhost:8080/","height":306},"executionInfo":{"status":"ok","timestamp":1619174199898,"user_tz":-180,"elapsed":5226,"user":{"displayName":"Роберт Сафиуллин","photoUrl":"","userId":"12047560743282496128"}},"outputId":"d176d65f-9d41-46f2-ac21-e6bf89a54467"},"source":["# нам необходима версия pillow  5.3.0\n","# удалим старую версию и установим новую\n","!pip uninstall -y Pillow\n","!pip install Pillow==5.3.0\n","import PIL\n","print(PIL.PILLOW_VERSION)\n","# здесь должна быть версия 5.3.0. если это не так перехгрузите данный ноутбук:\n","# Menu > Runtime > Restart Runtime"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Uninstalling Pillow-7.1.2:\n","  Successfully uninstalled Pillow-7.1.2\n","Collecting Pillow==5.3.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/8c/230204b8e968f6db00c765624f51cfd1ecb6aea57b25ba00b240ee3fb0bd/Pillow-5.3.0-cp37-cp37m-manylinux1_x86_64.whl (2.0MB)\n","\u001b[K     |████████████████████████████████| 2.0MB 19.7MB/s \n","\u001b[31mERROR: bokeh 2.3.1 has requirement pillow>=7.1.0, but you'll have pillow 5.3.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","\u001b[?25hInstalling collected packages: Pillow\n","Successfully installed Pillow-5.3.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["PIL"]}}},"metadata":{"tags":[]}},{"output_type":"stream","text":["7.1.2\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: PILLOW_VERSION is deprecated and will be removed in a future release. Use __version__ instead.\n","  \n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"TTQXgo_oYDx8"},"source":["\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"xA3o2xC3MlMI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619174224105,"user_tz":-180,"elapsed":29428,"user":{"displayName":"Роберт Сафиуллин","photoUrl":"","userId":"12047560743282496128"}},"outputId":"784f8e87-597b-44d8-cff2-768b397b19e5"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Eql8-ma0zBHc","executionInfo":{"status":"ok","timestamp":1619174224106,"user_tz":-180,"elapsed":29424,"user":{"displayName":"Роберт Сафиуллин","photoUrl":"","userId":"12047560743282496128"}}},"source":[""],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"GvWhlkiRMxih","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619174224107,"user_tz":-180,"elapsed":29421,"user":{"displayName":"Роберт Сафиуллин","photoUrl":"","userId":"12047560743282496128"}},"outputId":"0e5935af-16cc-48fc-b882-34da629b83cb"},"source":["!nvidia-smi\n","import torch\n","torch.cuda.is_available()"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Fri Apr 23 10:37:03 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   55C    P8    11W /  70W |      3MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"BD_8gK6PmgXk"},"source":["В нашем тесте будет 990 картнок, для которых вам будет необходимо предсказать класс."]},{"cell_type":"code","metadata":{"id":"naD6xsZzMxrC","colab":{"base_uri":"https://localhost:8080/","height":510},"executionInfo":{"status":"error","timestamp":1619174224557,"user_tz":-180,"elapsed":29866,"user":{"displayName":"Роберт Сафиуллин","photoUrl":"","userId":"12047560743282496128"}},"outputId":"9a46cba9-dff2-4b08-da32-7b719383a28d"},"source":["import pickle\n","import numpy as np\n","from skimage import io\n","\n","from tqdm import tqdm, tqdm_notebook\n","from PIL import Image\n","from pathlib import Path\n","\n","import torchvision.transforms as transforms\n","from multiprocessing.pool import ThreadPool\n","from sklearn.preprocessing import LabelEncoder\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn as nn\n","import random\n","from matplotlib import colors, pyplot as plt\n","%matplotlib inline\n","\n","# в sklearn не все гладко, чтобы в colab удобно выводить картинки \n","# мы будем игнорировать warnings\n","import warnings\n","warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n"],"execution_count":10,"outputs":[{"output_type":"error","ename":"ImportError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-44db49fc71fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mThreadPool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msvhn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSVHN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mphototour\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPhotoTour\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfakedata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFakeData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msemeion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSEMEION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0momniglot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOmniglot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/fakedata.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVisionDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mautoaugment\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0maccimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInterpolationMode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_interpolation_modes_from_int\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0maccimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional_pil\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional_tensor\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional_pil.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageOps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageEnhance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageFilter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mPILLOW_VERSION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/ImageOps.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0misStringType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'isStringType' from 'PIL._util' (/usr/local/lib/python3.7/dist-packages/PIL/_util.py)","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"WTdzMtgJP15N","executionInfo":{"status":"aborted","timestamp":1619174224543,"user_tz":-180,"elapsed":29848,"user":{"displayName":"Роберт Сафиуллин","photoUrl":"","userId":"12047560743282496128"}}},"source":["# разные режимы датасета \n","DATA_MODES = ['train', 'val', 'test']\n","# все изображения будут масштабированы к размеру 224x224 px\n","RESCALE_SIZE = 224\n","# работаем на видеокарте\n","DEVICE = torch.device(\"cuda\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cj32U5iTQUe4","executionInfo":{"status":"aborted","timestamp":1619174224544,"user_tz":-180,"elapsed":29845,"user":{"displayName":"Роберт Сафиуллин","photoUrl":"","userId":"12047560743282496128"}}},"source":["class SimpsonsDataset(Dataset):\n","    \"\"\"\n","    Датасет с картинками, который паралельно подгружает их из папок\n","    производит скалирование и превращение в торчевые тензоры\n","    \"\"\"\n","    def __init__(self, files, mode):\n","        super().__init__()\n","        # список файлов для загрузки\n","        self.files = sorted(files)\n","        # режим работы\n","        self.mode = mode\n","\n","        if self.mode not in DATA_MODES:\n","            print(f\"{self.mode} is not correct; correct modes: {DATA_MODES}\")\n","            raise NameError\n","\n","        self.len_ = len(self.files)\n","     \n","        self.label_encoder = LabelEncoder()\n","\n","        if self.mode != 'test':\n","            self.labels = [path.parent.name for path in self.files]\n","            self.label_encoder.fit(self.labels)\n","\n","            with open('label_encoder.pkl', 'wb') as le_dump_file:\n","                  pickle.dump(self.label_encoder, le_dump_file)\n","                      \n","    def __len__(self):\n","        return self.len_\n","      \n","    def load_sample(self, file):\n","        image = Image.open(file)\n","        image.load()\n","        return image\n","  \n","    def __getitem__(self, index):\n","        # для преобразования изображений в тензоры PyTorch и нормализации входа\n","        transform = transforms.Compose([\n","            transforms.ToTensor(),\n","            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n","        ])\n","        x = self.load_sample(self.files[index])\n","        x = self._prepare_sample(x)\n","        x = transform(x)\n","        if self.mode == 'test':\n","            return x\n","        else:\n","            label = self.labels[index]\n","            label_id = self.label_encoder.transform([label])\n","            y = label_id.item()\n","            return x, y\n","        \n","    def _prepare_sample(self, image):\n","        image = image.resize((RESCALE_SIZE, RESCALE_SIZE))\n","        return np.array(image)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j_odtTEzcaWH","executionInfo":{"status":"aborted","timestamp":1619174224545,"user_tz":-180,"elapsed":29842,"user":{"displayName":"Роберт Сафиуллин","photoUrl":"","userId":"12047560743282496128"}}},"source":["def imshow(inp, title=None, plt_ax=plt, default=False):\n","    \"\"\"Imshow для тензоров\"\"\"\n","    inp = inp.numpy().transpose((1, 2, 0))\n","    mean = np.array([0.485, 0.456, 0.406])\n","    std = np.array([0.229, 0.224, 0.225])\n","    inp = std * inp + mean\n","    inp = np.clip(inp, 0, 1)\n","    plt_ax.imshow(inp)\n","    if title is not None:\n","        plt_ax.set_title(title)\n","    plt_ax.grid(False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yUhzOq1zRJil","executionInfo":{"status":"aborted","timestamp":1619174224545,"user_tz":-180,"elapsed":29837,"user":{"displayName":"Роберт Сафиуллин","photoUrl":"","userId":"12047560743282496128"}}},"source":["TRAIN_DIR = Path('/content/gdrive/My Drive/simps/train/simpsons_dataset')\n","TEST_DIR = Path('/content/gdrive/My Drive/simps/testset/testset')\n","\n","train_val_files = sorted(list(TRAIN_DIR.rglob('*.jpg')))\n","test_files = sorted(list(TEST_DIR.rglob('*.jpg')))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TmPhhKKlRyCF","executionInfo":{"status":"aborted","timestamp":1619174224545,"user_tz":-180,"elapsed":29833,"user":{"displayName":"Роберт Сафиуллин","photoUrl":"","userId":"12047560743282496128"}}},"source":["from sklearn.model_selection import train_test_split\n","\n","train_val_labels = [path.parent.name for path in train_val_files]\n","train_files, val_files = train_test_split(train_val_files, test_size=0.25, \\\n","                                          stratify=train_val_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aAimOLjSQGTh","executionInfo":{"status":"aborted","timestamp":1619174224546,"user_tz":-180,"elapsed":29830,"user":{"displayName":"Роберт Сафиуллин","photoUrl":"","userId":"12047560743282496128"}}},"source":["val_dataset = SimpsonsDataset(val_files, mode='val')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GJ6-Rp68BWEs","executionInfo":{"status":"aborted","timestamp":1619174224546,"user_tz":-180,"elapsed":29826,"user":{"displayName":"Роберт Сафиуллин","photoUrl":"","userId":"12047560743282496128"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u6YcZk8vQR47"},"source":["### Построение нейросети\n","\n","Будем использовать VGG16 cо стандартными параметрами и lr=1e-4\n"]},{"cell_type":"code","metadata":{"id":"1PJcWAhuji-i","executionInfo":{"status":"aborted","timestamp":1619174224547,"user_tz":-180,"elapsed":29822,"user":{"displayName":"Роберт Сафиуллин","photoUrl":"","userId":"12047560743282496128"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e2mk7MNtcUhJ","executionInfo":{"status":"aborted","timestamp":1619174224547,"user_tz":-180,"elapsed":29818,"user":{"displayName":"Роберт Сафиуллин","photoUrl":"","userId":"12047560743282496128"}}},"source":["def fit_epoch(model, train_loader, criterion, optimizer):\n","    running_loss = 0.0\n","    running_corrects = 0\n","    processed_data = 0\n","  \n","    for inputs, labels in train_loader:\n","        inputs = inputs.to(DEVICE)\n","        labels = labels.to(DEVICE)\n","        optimizer.zero_grad()\n","\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        preds = torch.argmax(outputs, 1)\n","        running_loss += loss.item() * inputs.size(0)\n","        running_corrects += torch.sum(preds == labels.data)\n","        processed_data += inputs.size(0)\n","              \n","    train_loss = running_loss / processed_data\n","    train_acc = running_corrects.cpu().numpy() / processed_data\n","    return train_loss, train_acc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w_CD9--hcUjs","executionInfo":{"status":"aborted","timestamp":1619174224548,"user_tz":-180,"elapsed":29815,"user":{"displayName":"Роберт Сафиуллин","photoUrl":"","userId":"12047560743282496128"}}},"source":["def eval_epoch(model, val_loader, criterion):\n","    model.eval()\n","    running_loss = 0.0\n","    running_corrects = 0\n","    processed_size = 0\n","\n","    for inputs, labels in val_loader:\n","        inputs = inputs.to(DEVICE)\n","        labels = labels.to(DEVICE)\n","\n","        with torch.set_grad_enabled(False):\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            preds = torch.argmax(outputs, 1)\n","\n","        running_loss += loss.item() * inputs.size(0)\n","        running_corrects += torch.sum(preds == labels.data)\n","        processed_size += inputs.size(0)\n","    val_loss = running_loss / processed_size\n","    val_acc = running_corrects.double() / processed_size\n","    return val_loss, val_acc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NaxYIwB3cUmX","executionInfo":{"status":"aborted","timestamp":1619174224548,"user_tz":-180,"elapsed":29811,"user":{"displayName":"Роберт Сафиуллин","photoUrl":"","userId":"12047560743282496128"}}},"source":["def train(train_files, val_files, model, epochs, batch_size):\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","\n","    history = []\n","    log_template = \"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \\\n","    val_loss {v_loss:0.4f} train_acc {t_acc:0.4f} val_acc {v_acc:0.4f}\"\n","\n","    with tqdm(desc=\"epoch\", total=epochs) as pbar_outer:\n","        opt = torch.optim.Adam(model.parameters(),lr=0.0001)   #!!!!\n","        criterion = nn.CrossEntropyLoss()       # adam+CE\n","\n","        for epoch in range(epochs):\n","            train_loss, train_acc = fit_epoch(model, train_loader, criterion, opt)\n","            print(\"loss\", train_loss)\n","            \n","            val_loss, val_acc = eval_epoch(model, val_loader, criterion)\n","            history.append((train_loss, train_acc, val_loss, val_acc))\n","            \n","            pbar_outer.update(1)\n","            tqdm.write(log_template.format(ep=epoch+1, t_loss=train_loss,\\\n","                                           v_loss=val_loss, t_acc=train_acc, v_acc=val_acc))\n","            \n","    return history"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v6G7qbYqcUpL","executionInfo":{"status":"aborted","timestamp":1619174224549,"user_tz":-180,"elapsed":29808,"user":{"displayName":"Роберт Сафиуллин","photoUrl":"","userId":"12047560743282496128"}}},"source":["def predict(model, test_loader):\n","    with torch.no_grad():\n","        logits = []\n","    \n","        for inputs in test_loader:\n","            inputs = inputs.to(DEVICE)\n","            model.eval()\n","            outputs = model(inputs).cpu()\n","            logits.append(outputs)\n","            \n","    probs = nn.functional.softmax(torch.cat(logits), dim=-1).numpy()\n","    return probs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yzwhB4K3dQOC","executionInfo":{"status":"aborted","timestamp":1619174224549,"user_tz":-180,"elapsed":29803,"user":{"displayName":"Роберт Сафиуллин","photoUrl":"","userId":"12047560743282496128"}}},"source":["n_classes = len(np.unique(train_val_labels))\n","import torchvision.models as models\n","\n","#simple_cnn = SimpleCnn(n_classes).to(DEVICE)\n","simple_cnn = models.vgg16(pretrained=True).to(DEVICE)\n","\n","\n","print(\"we will classify :{}\".format(n_classes))\n","print(simple_cnn)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bo3UND5RdgVg"},"source":["Запустим обучение сети."]},{"cell_type":"code","metadata":{"id":"WDkcxZ1kfD4a","executionInfo":{"status":"aborted","timestamp":1619174224549,"user_tz":-180,"elapsed":29799,"user":{"displayName":"Роберт Сафиуллин","photoUrl":"","userId":"12047560743282496128"}}},"source":["if val_dataset is None:\n","    val_dataset = SimpsonsDataset(val_files, mode='val')\n","    \n","train_dataset = SimpsonsDataset(train_files, mode='train')\n","\n","# Подстроим сеть под задачу\n","simple_cnn.classifier[6] = nn.Linear(4096,n_classes).to(DEVICE)\n","\n","random.seed(0)\n","\n","np.random.seed(0)\n","\n","torch.manual_seed(0)\n","\n","torch.cuda.manual_seed(0)\n","\n","torch.backends.cudnn.deterministic = True\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wfrqI47DBiIs","executionInfo":{"status":"aborted","timestamp":1619174224550,"user_tz":-180,"elapsed":29796,"user":{"displayName":"Роберт Сафиуллин","photoUrl":"","userId":"12047560743282496128"}}},"source":["simple_cnn.classifier"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"83R_YKpuC-fN","executionInfo":{"status":"aborted","timestamp":1619174224550,"user_tz":-180,"elapsed":29791,"user":{"displayName":"Роберт Сафиуллин","photoUrl":"","userId":"12047560743282496128"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iDXoR8PIdfLD","executionInfo":{"status":"aborted","timestamp":1619174224550,"user_tz":-180,"elapsed":29787,"user":{"displayName":"Роберт Сафиуллин","photoUrl":"","userId":"12047560743282496128"}}},"source":["history = train(train_dataset, val_dataset, model=simple_cnn, epochs=20, batch_size=64)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PfWEbF7ST7ft","executionInfo":{"status":"aborted","timestamp":1619174224551,"user_tz":-180,"elapsed":29784,"user":{"displayName":"Роберт Сафиуллин","photoUrl":"","userId":"12047560743282496128"}}},"source":["    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b4p_X9Y3T7TQ","executionInfo":{"status":"aborted","timestamp":1619174224551,"user_tz":-180,"elapsed":29780,"user":{"displayName":"Роберт Сафиуллин","photoUrl":"","userId":"12047560743282496128"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JirSZ1yWT7FN","executionInfo":{"status":"aborted","timestamp":1619174224551,"user_tz":-180,"elapsed":29775,"user":{"displayName":"Роберт Сафиуллин","photoUrl":"","userId":"12047560743282496128"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EQ2lOAuqT6uw","executionInfo":{"status":"aborted","timestamp":1619174224552,"user_tz":-180,"elapsed":29772,"user":{"displayName":"Роберт Сафиуллин","photoUrl":"","userId":"12047560743282496128"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7qMAdL_BduXZ"},"source":["Построим кривые обучения"]},{"cell_type":"code","metadata":{"id":"2ryD_9yFdfNr","executionInfo":{"status":"aborted","timestamp":1619174224552,"user_tz":-180,"elapsed":29766,"user":{"displayName":"Роберт Сафиуллин","photoUrl":"","userId":"12047560743282496128"}}},"source":["loss, acc, val_loss, val_acc = zip(*history)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GpQDWGkfdfQ5","executionInfo":{"status":"aborted","timestamp":1619174224553,"user_tz":-180,"elapsed":29759,"user":{"displayName":"Роберт Сафиуллин","photoUrl":"","userId":"12047560743282496128"}}},"source":["plt.figure(figsize=(15, 9))\n","plt.plot(loss, label=\"train_loss\")\n","plt.plot(val_loss, label=\"val_loss\")\n","plt.legend(loc='best')\n","plt.xlabel(\"epochs\")\n","plt.ylabel(\"loss\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"caivVFeAN9SY","executionInfo":{"status":"aborted","timestamp":1619174224553,"user_tz":-180,"elapsed":29752,"user":{"displayName":"Роберт Сафиуллин","photoUrl":"","userId":"12047560743282496128"}}},"source":["idxs = list(map(int, np.random.uniform(0,1000, 20)))\n","imgs = [val_dataset[id][0].unsqueeze(0) for id in idxs]\n","\n","probs_ims = predict(simple_cnn, imgs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t-0pRdHnQQKM","executionInfo":{"status":"aborted","timestamp":1619174224553,"user_tz":-180,"elapsed":29746,"user":{"displayName":"Роберт Сафиуллин","photoUrl":"","userId":"12047560743282496128"}}},"source":["label_encoder = pickle.load(open(\"label_encoder.pkl\", 'rb'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GNMFc7sfQh1a","executionInfo":{"status":"aborted","timestamp":1619174224554,"user_tz":-180,"elapsed":29741,"user":{"displayName":"Роберт Сафиуллин","photoUrl":"","userId":"12047560743282496128"}}},"source":["y_pred = np.argmax(probs_ims,-1)\n","\n","actual_labels = [val_dataset[id][1] for id in idxs]\n","\n","preds_class = [label_encoder.classes_[i] for i in y_pred]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oRWPGIv3bN2X","executionInfo":{"status":"aborted","timestamp":1619174224554,"user_tz":-180,"elapsed":29737,"user":{"displayName":"Роберт Сафиуллин","photoUrl":"","userId":"12047560743282496128"}}},"source":["y_pred=np.array(y_pred)\n","actual_labels=np.array(actual_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iVePL0-BKHrF"},"source":[" Вычислим целевую метрику f1 на валидационной выборке."]},{"cell_type":"code","metadata":{"id":"_h-9dDWsKGU-","executionInfo":{"status":"aborted","timestamp":1619174224554,"user_tz":-180,"elapsed":29732,"user":{"displayName":"Роберт Сафиуллин","photoUrl":"","userId":"12047560743282496128"}}},"source":["from sklearn.metrics import f1_score\n","\n","f1_score(actual_labels, y_pred, average='macro')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tq3nMIqHeFFC","executionInfo":{"status":"aborted","timestamp":1619174224555,"user_tz":-180,"elapsed":29728,"user":{"displayName":"Роберт Сафиуллин","photoUrl":"","userId":"12047560743282496128"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9UTbU0Zbc6Hb","executionInfo":{"status":"aborted","timestamp":1619174224555,"user_tz":-180,"elapsed":29724,"user":{"displayName":"Роберт Сафиуллин","photoUrl":"","userId":"12047560743282496128"}}},"source":["test_dataset = SimpsonsDataset(test_files, mode=\"test\")\n","test_loader = DataLoader(test_dataset, shuffle=False, batch_size=64)\n","probs = predict(simple_cnn, test_loader)\n","  \n","\n","preds = label_encoder.inverse_transform(np.argmax(probs, axis=1))\n","test_filenames = [path.name for path in test_dataset.files]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_rTtbV1teD2k","executionInfo":{"status":"aborted","timestamp":1619174224555,"user_tz":-180,"elapsed":29719,"user":{"displayName":"Роберт Сафиуллин","photoUrl":"","userId":"12047560743282496128"}}},"source":["! ls \n","preds.shape\n","submit = pd.DataFrame({'Id': test_filenames, 'Expected': preds})\n","submit.head()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yw0zZ-Hdd89s","executionInfo":{"status":"aborted","timestamp":1619174224556,"user_tz":-180,"elapsed":29716,"user":{"displayName":"Роберт Сафиуллин","photoUrl":"","userId":"12047560743282496128"}}},"source":["import pandas as pd\n","my_submit = pd.read_csv(\"/content/gdrive/My Drive/simps/sample_submission.csv\")\n","# my_submit = pd.DataFrame({'Image_id': test_filenames, 'Expected': preds})\n","my_submit.Expected=preds"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VIYaqa20iYTL","executionInfo":{"status":"aborted","timestamp":1619174224556,"user_tz":-180,"elapsed":29710,"user":{"displayName":"Роберт Сафиуллин","photoUrl":"","userId":"12047560743282496128"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5rdlyMKtiYe2","executionInfo":{"status":"aborted","timestamp":1619174224556,"user_tz":-180,"elapsed":29705,"user":{"displayName":"Роберт Сафиуллин","photoUrl":"","userId":"12047560743282496128"}}},"source":["submit.to_csv('/content/gdrive/My Drive/simps/simple_cnn_baseline.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h3M9SQZ7MuUq"},"source":["## Приключение?\n","\n","А теперь самое интересное, мы сделали простенькую сверточную сеть и смогли отправить сабмит, но получившийся скор нас явно не устраивает. Надо с этим что-то сделать. \n","\n","Несколько срочныйх улучшейни для нашей сети, которые наверняка пришли Вам в голову: \n","\n","\n","*   Учим дольше и изменяем гиперпараметры сети\n","*  learning rate, batch size, нормализация картинки и вот это всё\n","*   Кто же так строит нейронные сети? А где пулинги и батч нормы? Надо добавлять\n","*  Ну разве Адам наше все? [adamW](https://www.fast.ai/2018/07/02/adam-weight-decay/) для практика, [статейка для любителей](https://openreview.net/pdf?id=ryQu7f-RZ) (очень хороший анализ), [наши ](https://github.com/MichaelKonobeev/adashift/) эксперименты для заинтересованных.\n","\n","* Ну разве это deep learning? Вот ResNet и Inception, которые можно зафайнтьюнить под наши данные, вот это я понимаю (можно и обучить в колабе, а можно и [готовые](https://github.com/Cadene/pretrained-models.pytorch) скачать).\n","\n","* Данных не очень много, можно их аугументировать и  доучититься на новом датасете ( который уже будет состоять из, как  пример аугументации, перевернутых изображений)\n","\n","* Стоит подумать об ансамблях\n","\n","\n","Надеюсь, что у Вас получится!\n","\n","![alt text](https://pbs.twimg.com/profile_images/798904974986113024/adcQiVdV.jpg)\n"]},{"cell_type":"code","metadata":{"id":"Lpl_kRwa9rFe","executionInfo":{"status":"aborted","timestamp":1619174224557,"user_tz":-180,"elapsed":29702,"user":{"displayName":"Роберт Сафиуллин","photoUrl":"","userId":"12047560743282496128"}}},"source":[""],"execution_count":null,"outputs":[]}]}